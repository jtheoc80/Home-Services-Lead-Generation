name: Data Quality Validation

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      debug:
        description: "Enable debug logging"
        required: false
        type: boolean
        default: false
  # Scheduled run at 5:15 AM UTC daily
  schedule:
    - cron: "15 5 * * *"

env:
  PYTHON_VERSION: "3.11"

jobs:
  validate:
    runs-on: ubuntu-latest
    concurrency:
      group: data-quality-validation
      cancel-in-progress: false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # Install permit_leads requirements
        if [ -f "permit_leads/requirements.txt" ]; then
          pip install -r permit_leads/requirements.txt
        fi
        # Install Great Expectations
        pip install great_expectations

    - name: Create directories
      run: |
        mkdir -p data logs data_quality/uncommitted

    - name: Preflight environment check
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      run: |
        echo "Checking environment variables..."
        if [ -z "$DATABASE_URL" ] && [ -z "$SUPABASE_URL" ]; then
          echo "::warning title=No database configured::Neither DATABASE_URL nor SUPABASE_URL is set"
          echo "Will use sample data for validation"
        else
          echo "Database configuration found"
          if [ -n "$DATABASE_URL" ]; then
            echo "::add-mask::$DATABASE_URL"
          fi
          if [ -n "$SUPABASE_URL" ]; then
            echo "::add-mask::$SUPABASE_URL"
          fi
          if [ -n "$SUPABASE_SERVICE_ROLE_KEY" ]; then
            echo "::add-mask::$SUPABASE_SERVICE_ROLE_KEY"
          fi
        fi

    - name: Build sample batch of data
      id: data_export
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      run: |
        echo "Exporting yesterday's permit data..."
        
        # Set debug mode if requested
        if [ "${{ inputs.debug }}" = "true" ]; then
          export DEBUG=1
          echo "Debug mode enabled"
        fi
        
        # Run the export script
        python export_yesterday_csv.py --output data/yesterday.csv --verbose
        
        # Check if data was exported
        if [ -f "data/yesterday.csv" ]; then
          RECORD_COUNT=$(tail -n +2 data/yesterday.csv | wc -l)
          echo "record_count=$RECORD_COUNT" >> "$GITHUB_OUTPUT"
          echo "✅ Exported $RECORD_COUNT records to data/yesterday.csv"
          
          # Show first few lines for debugging
          echo "Sample data:"
          head -n 5 data/yesterday.csv
        else
          echo "❌ Failed to create data/yesterday.csv"
          exit 1
        fi

    - name: Initialize Great Expectations
      run: |
        echo "Initializing Great Expectations context..."
        cd data_quality
        
        # Create basic great_expectations.yml if it doesn't exist
        if [ ! -f "great_expectations.yml" ]; then
          cat > great_expectations.yml << 'EOF'
        # Welcome to Great Expectations! Always know what to expect from your data.
        #
        # Here you can define datasources, batch kwargs generators, integrations and
        # more. This file is intended to be committed and distributed as part of your
        # project.
        #
        # Please see the great_expectations.yml file in the great_expectations/ directory
        # for more details.
        
        config_version: 3.0
        
        # Datasources tell Great Expectations where to find data
        datasources: {}
        
        config_variables_file_path: uncommitted/config_variables.yml
        
        # The plugins_directory will be added to your python path for custom modules
        # used to override and extend Great Expectations.
        plugins_directory: plugins/
        
        stores:
        # Stores are configurable places to store things like Expectations, Validations
        # Data Docs, and more. These are for advanced users only - most users can simply
        # leave this section alone.
        #
        # Three stores are required: expectations, validations, and
        # evaluation_parameters, and must exist with a valid store entry. Additional
        # stores can be configured for uses such as data_docs, etc.
          expectations_store:
            class_name: ExpectationsStore
            store_backend:
              class_name: TupleFilesystemStoreBackend
              base_directory: expectations/
        
          validations_store:
            class_name: ValidationsStore
            store_backend:
              class_name: TupleFilesystemStoreBackend
              base_directory: uncommitted/validations/
        
          evaluation_parameter_store:
            class_name: EvaluationParameterStore
        
          checkpoint_store:
            class_name: CheckpointStore
            store_backend:
              class_name: TupleFilesystemStoreBackend
              base_directory: checkpoints/
        
        expectations_store_name: expectations_store
        validations_store_name: validations_store
        evaluation_parameter_store_name: evaluation_parameter_store
        checkpoint_store_name: checkpoint_store
        
        data_docs_sites:
        # Data Docs make it simple to visualize data quality in your project. These
        # include Expectations, Validations & Profiles. The are built for all
        # Datasources from JSON artifacts in the local repo including validations &
        # profiles from the uncommitted directory. Read more at https://docs.greatexpectations.io/docs/reference/core_concepts/data_docs/
          local_site:
            class_name: SiteBuilder
            # set to false to hide how-to buttons in Data Docs
            show_how_to_buttons: true
            store_backend:
              class_name: TupleFilesystemStoreBackend
              base_directory: uncommitted/data_docs/local_site/
            site_index_builder:
              class_name: DefaultSiteIndexBuilder
        
        anonymous_usage_statistics:
          data_context_id: 00000000-1111-2222-3333-444444444444
          enabled: false
        
        notebooks:
        EOF
        fi
        
        # Create config variables file
        mkdir -p uncommitted
        cat > uncommitted/config_variables.yml << 'EOF'
        # Variables can be used to substitute values in your great_expectations.yml
        
        # For example, ${my_var} can be substituted for any value in your config file
        # my_var: my_value
        EOF
        
        # Create required directories
        mkdir -p expectations checkpoints uncommitted/validations uncommitted/data_docs

    - name: Run Great Expectations checkpoint
      id: validation
      continue-on-error: true  # Allow graceful failure
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      run: |
        echo "Running Great Expectations validation..."
        
        # Set working directory to root to access all modules
        cd "$GITHUB_WORKSPACE"
        
        # Run checkpoint validation with error handling
        python -c "
        import sys
        import os
        import json
        
        # Add current directory to Python path
        sys.path.insert(0, '.')
        
        try:
            from data_quality.permits_validation import run_permits_checkpoint
            
            # Run the checkpoint
            print('Starting permits_checkpoint validation...')
            results = run_permits_checkpoint()
            
            # Output results
            print('Validation Results:')
            print(json.dumps(results, indent=2, default=str))
            
            # Set GitHub outputs
            success = results.get('success', False)
            print(f'Validation Success: {success}')
            
            # Write results to file for artifact upload
            with open('data_quality/validation_results.json', 'w') as f:
                json.dump(results, f, indent=2, default=str)
            
            # Set GitHub step output
            with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                f.write(f'validation_success={str(success).lower()}\n')
                f.write(f'run_id={results.get(\"run_id\", \"unknown\")}\n')
            
            # Exit with appropriate code (but continue-on-error will handle it)
            sys.exit(0 if success else 1)
            
        except ImportError as e:
            print(f'Import error: {e}')
            print('Running basic validation instead...')
            
            # Fallback validation - just check if CSV exists and has data
            if os.path.exists('data/yesterday.csv'):
                with open('data/yesterday.csv', 'r') as f:
                    lines = f.readlines()
                    if len(lines) > 1:  # Header + at least one data row
                        print(f'✅ Basic validation passed: {len(lines)-1} records found')
                        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                            f.write('validation_success=true\n')
                            f.write('run_id=basic_validation\n')
                        sys.exit(0)
            
            print('❌ Basic validation failed: No valid data found')
            with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                f.write('validation_success=false\n')
                f.write('run_id=basic_validation_failed\n')
            sys.exit(1)
            
        except Exception as e:
            print(f'Validation error: {e}')
            import traceback
            traceback.print_exc()
            import hashlib
            error_hash = hashlib.sha256(str(e).encode('utf-8')).hexdigest()[:16]
            with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                f.write('validation_success=false\n')
                f.write(f'run_id=error_{error_hash}\n')
            sys.exit(1)
        "

    - name: Generate Data Docs
      if: always()  # Run even if validation failed
      run: |
        echo "Generating Great Expectations Data Docs..."
        
        # Try to build data docs
        cd data_quality
        python -c "
        import great_expectations as gx
        try:
            context = gx.get_context()
            context.build_data_docs()
            print('✅ Data Docs generated successfully')
        except Exception as e:
            print(f'Data Docs generation failed: {e}')
            print('Creating basic HTML report...')
            
            # Create a basic HTML report
            import os
            os.makedirs('uncommitted/data_docs/local_site', exist_ok=True)
            
            with open('uncommitted/data_docs/local_site/index.html', 'w') as f:
                f.write('''
                <!DOCTYPE html>
                <html>
                <head>
                    <title>Data Quality Validation Report</title>
                    <style>
                        body { font-family: Arial, sans-serif; margin: 40px; }
                        .header { background: #f0f0f0; padding: 20px; border-radius: 5px; }
                        .success { color: green; }
                        .error { color: red; }
                        .info { background: #e7f3ff; padding: 10px; border-radius: 3px; margin: 10px 0; }
                    </style>
                </head>
                <body>
                    <div class=\"header\">
                        <h1>Data Quality Validation Report</h1>
                        <p>Generated: ''' + str(__import__('datetime').datetime.now()) + '''</p>
                    </div>
                    <div class=\"info\">
                        <h2>Validation Summary</h2>
                        <p>This is a basic validation report. Full Great Expectations integration is pending.</p>
                    </div>
                </body>
                </html>
                ''')
            print('Created basic HTML report')
        "

    - name: Upload validation artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: data-quality-validation-${{ github.run_id }}
        path: |
          data/yesterday.csv
          data_quality/uncommitted/data_docs/
          data_quality/validation_results.json
          data_quality/uncommitted/validations/
          logs/
        if-no-files-found: warn
        retention-days: 7

    - name: Upload Data Docs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: great-expectations-data-docs-${{ github.run_id }}
        path: data_quality/uncommitted/data_docs/
        if-no-files-found: warn
        retention-days: 14

    - name: Validation Summary
      if: always()
      run: |
        echo "## Data Quality Validation Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Workflow Run:** ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Data Records:** ${{ steps.data_export.outputs.record_count || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Validation Success:** ${{ steps.validation.outputs.validation_success || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Run ID:** ${{ steps.validation.outputs.run_id || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.validation.outputs.validation_success }}" = "true" ]; then
          echo "✅ **Data quality validation PASSED**" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Data quality validation FAILED or encountered errors**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Please review the validation artifacts for details." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Artifacts Generated" >> $GITHUB_STEP_SUMMARY
        echo "- Sample data: \`data/yesterday.csv\`" >> $GITHUB_STEP_SUMMARY
        echo "- Data Docs: Great Expectations HTML reports" >> $GITHUB_STEP_SUMMARY
        echo "- Validation results: JSON format results" >> $GITHUB_STEP_SUMMARY