---
name: Self-Hosted Houston Backfill

on:
  # Manual trigger with parameters
  workflow_dispatch:
    inputs:
      archive_weeks:
        description: 'Number of weeks to backfill'
        required: false
        default: '12'
        type: string
      create_leads_limit:
        description: 'Number of leads to create (max 100)'
        required: false
        default: '50'
        type: string

  # Weekly schedule - Sundays at 2 AM UTC
  schedule:
    - cron: "0 2 * * 0"

# Prevent overlapping scrapes on self-hosted runners
concurrency:
  group: scrape-${{ github.ref }}
  cancel-in-progress: false

jobs:
  backfill:
    runs-on: [self-hosted, linux, x64, scrape]
    timeout-minutes: 60

    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      ARCHIVE_WEEKS: ${{ inputs.archive_weeks || '12' }}

    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Sanity check required env
        run: |
          set -euo pipefail
          missing=0
          for v in SUPABASE_URL SUPABASE_SERVICE_ROLE_KEY USER_AGENT; do
            if [ -z "${!v:-}" ]; then echo "MISSING $v"; missing=1; fi
          done
          # Add city-specific vars below (uncomment what applies)
          # Dallas
          # for v in DALLAS_ARCGIS_URL; do [ -z "${!v:-}" ] && echo "MISSING $v" && missing=1; done
          # Austin
          # for v in AUSTIN_SODA_APP_TOKEN AUSTIN_DATASET_ID; do [ -z "${!v:-}" ] && echo "MISSING $v" && missing=1; done
          # San Antonio
          # for v in SANANTONIO_SODA_APP_TOKEN SAN_ANTONIO_DATASET_ID; do [ -z "${!v:-}" ] && echo "MISSING $v" && missing=1; done
          # Houston
          # for v in HOUSTON_WEEKLY_URL HOUSTON_SOLD_URL; do [ -z "${!v:-}" ] && echo "MISSING $v" && missing=1; done
          exit $missing
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          USER_AGENT: ${{ secrets.USER_AGENT || 'LeadLedgerETL/1.0' }}

      - name: Preflight connectivity
        run: |
          set -euxo pipefail
          # Un-comment the checks you need. We print only the status line.
          # Dallas ArcGIS:
          # curl -sS --get "${DALLAS_ARCGIS_URL}" \
          #   --data-urlencode 'where=1=1' \
          #   --data-urlencode 'outFields=*' \
          #   --data-urlencode 'resultRecordCount=1' \
          #   --data-urlencode 'f=json' | head -c 200 | tr -d '\n' && echo

          # Austin Socrata:
          # curl -sS -H "X-App-Token: ${AUSTIN_SODA_APP_TOKEN}" \
          #   "https://data.austintexas.gov/resource/${AUSTIN_DATASET_ID}.json?\$limit=1" | head -c 200 | tr -d '\n' && echo

          # San Antonio Socrata:
          # curl -sS -H "X-App-Token: ${SANANTONIO_SODA_APP_TOKEN}" \
          #   "https://data.sanantonio.gov/resource/${SAN_ANTONIO_DATASET_ID}.json?\$limit=1" | head -c 200 | tr -d '\n' && echo

          # Houston weekly/sold landing pages:
          # curl -sS -I "${HOUSTON_WEEKLY_URL}" | head -n1
          # curl -sS -I "${HOUSTON_SOLD_URL}"   | head -n1

      - name: Preflight - Check secrets
        run: |
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_SERVICE_ROLE_KEY" ]; then
            echo "::error::Missing required Supabase secrets"
            exit 1
          fi
          echo "âœ… Required secrets are configured"

      - name: Connectivity check
        run: |
          set -Eeuo pipefail
          echo "ðŸ”— Testing connectivity to Houston permits endpoint..."
          curl -sS -I \
            https://www.houstontx.gov/planning/DevelopRegs/dev_reports.html \
            | head -n1
          echo "âœ… Houston permits endpoint is reachable"

      - name: Run Houston archives backfill
        run: |
          echo "ðŸ“¥ Starting Houston archives backfill for $ARCHIVE_WEEKS weeks..."
          npx tsx scripts/ingest-coh-archives.ts

      - name: Create leads from fresh permits
        env:
          LEADS_LIMIT: ${{ inputs.create_leads_limit || '50' }}
        run: |
          echo "ðŸŽ¯ Creating up to $LEADS_LIMIT leads from fresh permits..."

          # Validate leads limit (max 100 for safety)
          if [ "$LEADS_LIMIT" -gt 100 ]; then
            echo "âš ï¸  Leads limit reduced to 100 for safety (was $LEADS_LIMIT)"
            LEADS_LIMIT=100
          fi

          # Call Supabase function to create leads
          response=$(curl -sS \
            "$SUPABASE_URL/rest/v1/rpc/upsert_leads_from_permits_limit" \
            -H "apikey: $SUPABASE_SERVICE_ROLE_KEY" \
            -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_KEY" \
            -H "Content-Type: application/json" \
            -d "{\"p_limit\":$LEADS_LIMIT,\"p_days\":365}")

          echo "ðŸ“Š Lead creation response: $response"

          # Try to extract counts for reporting
          if command -v jq >/dev/null 2>&1; then
            inserted=$(echo "$response" | jq -r '.inserted_count // "unknown"' \
              2>/dev/null)
            updated=$(echo "$response" | jq -r '.updated_count // "unknown"' \
              2>/dev/null)
            echo "âœ… Leads processed - Inserted: $inserted, Updated: $updated"
          fi

      - name: Workflow Summary
        if: always()
        run: |
          echo "## Houston Backfill Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner**: Self-hosted scraper" >> $GITHUB_STEP_SUMMARY
          echo "- **Archive Weeks**: $ARCHIVE_WEEKS" >> $GITHUB_STEP_SUMMARY
          echo "- **Leads Limit**: ${{ inputs.create_leads_limit || '50' }}" \
            >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY

          # Add concurrency info
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Concurrency Control" >> $GITHUB_STEP_SUMMARY
          echo "- **Group**: scrape-${{ github.ref }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Cancel in Progress**: false (prevents overlapping scrapes)" \
            >> $GITHUB_STEP_SUMMARY