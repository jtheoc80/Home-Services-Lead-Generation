name: City of Houston ETL
on:
  schedule: [{ cron: "0 6 * * *" }]
  workflow_dispatch:
    inputs:
      include_archives:
        description: 'Include archives backfill (last 12 weeks)'
        required: false
        default: 'false'
        type: boolean
      archive_weeks:
        description: 'Number of weeks to backfill from archives'
        required: false
        default: '12'
        type: string

permissions: { contents: read }

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run:
    runs-on: [self-hosted, linux, x64, scrape]
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      HOUSTON_WEEKLY_XLSX_URL: ${{ secrets.HOUSTON_WEEKLY_XLSX_URL }}
      HOUSTON_SOLD_PERMITS_URL: ${{ secrets.HOUSTON_SOLD_PERMITS_URL }}
      DAYS: ${{ vars.DAYS || '7' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: 
          node-version: '20'
          cache: 'npm'
      - run: npm ci
      - name: Connectivity check (Houston weekly page)
        run: |
          set -Eeuo pipefail
          URL="https://www.houstontx.gov/planning/DevelopRegs/dev_reports.html"
          echo "Checking $URL"
          getent ahosts www.houstontx.gov || true
          STATUS=$(curl -sS -I -A "LeadLedgerETL/1.0 (+github-actions)" -o /dev/null -w "%{http_code}" "$URL" || true)
          echo "HTTP_STATUS=$STATUS"
          test "$STATUS" = "200" || { echo "❌ Houston page unreachable ($STATUS)"; exit 1; }
      - name: Ingest → Upsert → Build Leads
        run: |
          mkdir -p logs
          npm run ingest:coh 2>&1 | tee logs/etl_output.log

      - name: Summary
        if: always()
        run: |
          echo "### COH ETL" >> "$GITHUB_STEP_SUMMARY"
          if test -f logs/etl-summary.json; then
            cat logs/etl-summary.json >> "$GITHUB_STEP_SUMMARY"
          fi
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coh-logs-${{ github.run_id }}
          path: logs/

  backfill-archives:
    runs-on: [self-hosted, linux, x64, scrape]
    if: github.event.inputs.include_archives == 'true'
    needs: run
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      ARCHIVE_WEEKS: ${{ github.event.inputs.archive_weeks || '12' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: 
          node-version: '20'
          cache: 'npm'
      - run: npm ci
      - name: Backfill Houston archives (last ${{ github.event.inputs.archive_weeks || '12' }} weeks)
        run: |
          node -v
          npx tsx scripts/ingest-coh-archives.ts

      - name: Archives Summary
        if: always()
        run: |
          echo "### Houston Archives Backfill" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Weeks processed**: ${{ github.event.inputs.archive_weeks || '12' }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Status**: ${{ job.status == 'success' && '✅ Success' || '❌ Failed' }}" >> "$GITHUB_STEP_SUMMARY"