name: Harris County Permit Scraper

on:
  schedule:
    # Run every hour
    - cron: '0 * * * *'
  workflow_dispatch:
    inputs:
      days:
        description: 'Days to look back'
        required: false
        default: '1'
        type: string
      sample_data:
        description: 'Use sample data (for testing)'
        required: false
        default: false
        type: boolean

env:
  SAMPLE_DATA: ${{ (github.event_name == 'workflow_dispatch' && inputs.sample_data) && '1' || '0' }}
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
  HC_ISSUED_PERMITS_URL: ${{ secrets.HC_ISSUED_PERMITS_URL }}

jobs:
  scrape-harris-permits:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r permit_leads/requirements.txt
        
    - name: Create data directory
      run: |
        mkdir -p data/permits/{raw,aggregate}
        
    - name: Check for 24h zero results
      id: check_recent
      run: |
        # Check if we have any Harris County data from the last 24 hours
        YESTERDAY=$(date -d '1 day ago' +%Y-%m-%d)
        TODAY=$(date +%Y-%m-%d)
        
        RECENT_FILES=0
        if [ -d "data/permits" ]; then
          RECENT_FILES=$(find data/permits -name "*harris*" -name "*${YESTERDAY}*" -o -name "*harris*" -name "*${TODAY}*" | wc -l)
        fi
        
        echo "recent_files=${RECENT_FILES}" >> $GITHUB_OUTPUT
        echo "Found ${RECENT_FILES} recent Harris County files"
        
    - name: Run Harris County permit scraper
      id: scrape
      run: |
        DAYS="${{ github.event.inputs.days || '1' }}"
        
        echo "Scraping Harris County permits for the last ${DAYS} days..."
        python -m permit_leads scrape --jurisdiction tx-harris --days "${DAYS}" --formats csv sqlite jsonl --verbose
        
        # Count new permits from today's run
        TODAY=$(date +%Y-%m-%d)
        NEW_PERMITS=0
        
        # Check CSV files for permit count
        if [ -f "data/permits/aggregate/permits_${TODAY}.csv" ]; then
          NEW_PERMITS=$(tail -n +2 "data/permits/aggregate/permits_${TODAY}.csv" | wc -l)
        fi
        
        echo "new_permits=${NEW_PERMITS}" >> $GITHUB_OUTPUT
        echo "Found ${NEW_PERMITS} new permits today"
        
    - name: Fail if zero results for 24h
      if: steps.check_recent.outputs.recent_files == '0' && steps.scrape.outputs.new_permits == '0'
      run: |
        echo "âŒ No Harris County permits found in the last 24 hours"
        echo "This may indicate a problem with the scraper or data source"
        exit 1
        
    - name: Commit and push data
      if: ${{ steps.scrape.outputs.new_permits != '0' }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        if git diff --staged --quiet; then
          echo "No changes to commit"
          exit 0
        fi
        TODAY=$(date +%Y-%m-%d)
        git commit -m "Update Harris County permit data for ${TODAY}" \
                    -m "${{ steps.scrape.outputs.new_permits }} permits processed" \
                    -m "Automated Harris County scrape"
        git push
        
    - name: Set date output
      id: set_date
      run: echo "date=$(date +%Y-%m-%d)" >> "$GITHUB_OUTPUT"

    - name: Upload data artifacts
      if: ${{ steps.scrape.outputs.new_permits != '0' }}
      uses: actions/upload-artifact@v4
      with:
        name: harris-county-permits-${{ steps.set_date.outputs.date }}
        path: data/
        retention-days: 30