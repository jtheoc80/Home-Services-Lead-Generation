name: Harris County Permit Scraper

on:
  schedule:
    # Run every hour
    - cron: '0 * * * *'
  workflow_dispatch:
    inputs:
      days:
        description: 'Days to look back'
        required: false
        default: '1'
        type: string
      sample_data:
        description: 'Use sample data (for testing)'
        required: false
        default: false
        type: boolean

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
  HC_ISSUED_PERMITS_URL: ${{ secrets.HC_ISSUED_PERMITS_URL }}

jobs:
  dryrun:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    
    env:
      ETL_ALLOW_EMPTY: 1
      SAMPLE_DATA: 1
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      HC_ISSUED_PERMITS_URL: ${{ secrets.HC_ISSUED_PERMITS_URL }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r permit_leads/requirements.txt
        
    - name: Create directories
      run: |
        mkdir -p data/permits/{raw,aggregate}
        mkdir -p logs artifacts
        
    - name: Run Harris County permit scraper (dry-run with sample data)
      run: |
        echo "🔧 Running dry-run with sample data and ETL_ALLOW_EMPTY=1"
        echo "Sample data mode: ${SAMPLE_DATA}"
        echo "ETL allow empty: ${ETL_ALLOW_EMPTY}"
        
        # Run with sample data for 1 day
        python -m permit_leads scrape --jurisdiction tx-harris --days 1 --formats csv sqlite jsonl --verbose
        SCRAPER_EXIT_CODE=$?
        if [ $SCRAPER_EXIT_CODE -ne 0 ]; then
          echo "::error::Harris County permit scraper failed with exit code $SCRAPER_EXIT_CODE"
        fi
        # Continue regardless of scraper result
        
        # Ensure artifacts are created even when empty
        [ -f scripts/ensure_artifacts.py ] && python scripts/ensure_artifacts.py || true
        
    - name: Upload logs and data artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: harris-dryrun-logs-${{ github.run_number }}
        path: |
          logs/
          data/
          artifacts/
        retention-days: 7
    
  scrape-harris-permits:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r permit_leads/requirements.txt
        
    - name: Create data directory
      run: |
        mkdir -p data/permits/{raw,aggregate}
        
    - name: "Preflight: verify required secrets"
      id: preflight
      shell: bash
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        HC_ISSUED_PERMITS_URL: ${{ secrets.HC_ISSUED_PERMITS_URL }}
      run: |
        ok=1
        for v in SUPABASE_URL SUPABASE_SERVICE_ROLE_KEY HC_ISSUED_PERMITS_URL; do
          val="${!v}"
          if [ -z "$val" ]; then
            echo "::error title=$v missing::Set $v in GitHub → Settings → Secrets and variables → Actions"
            ok=0
          else
            echo "::add-mask::$val"
          fi
        done
        echo "ok=$ok" >> "$GITHUB_OUTPUT"
        [ "$ok" -eq 1 ]

    - name: "Preflight: test Supabase connectivity"
      if: ${{ steps.preflight.outputs.ok == '1' }}
      id: supa
      shell: bash
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      run: |
        code=$(curl -s -o /dev/null -w "%{http_code}" \
          -H "apikey: $SUPABASE_SERVICE_ROLE_KEY" \
          -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_KEY" \
          -H "Prefer: count=exact, head=true" \
          "$SUPABASE_URL/rest/v1/leads?select=id&limit=1")
        echo "http_code=$code" >> "$GITHUB_OUTPUT"
        if [ "$code" != "200" ] && [ "$code" != "206" ]; then
          echo "::warning title=Supabase REST check failed::HTTP $code"
        fi
        
    - name: Check for 24h zero results
      id: check_recent
      run: |
        # Check if we have any Harris County data from the last 24 hours
        YESTERDAY=$(date -d '1 day ago' +%Y-%m-%d)
        TODAY=$(date +%Y-%m-%d)
        
        RECENT_FILES=0
        if [ -d "data/permits" ]; then
          RECENT_FILES=$(find data/permits -name "*harris*" -name "*${YESTERDAY}*" -o -name "*harris*" -name "*${TODAY}*" | wc -l)
        fi
        
        echo "recent_files=${RECENT_FILES}" >> $GITHUB_OUTPUT
        echo "Found ${RECENT_FILES} recent Harris County files"
        
    - name: Run Harris County permit scraper
      if: ${{ steps.preflight.outputs.ok == '1' }}
      id: scrape
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        HC_ISSUED_PERMITS_URL: ${{ secrets.HC_ISSUED_PERMITS_URL }}
      run: |
        DAYS="${{ inputs.days }}" ; [ -z "$DAYS" ] && DAYS="1"
        [ "${{ inputs.sample_data }}" = "true" ] && export SAMPLE_DATA=1 || export SAMPLE_DATA=0
        
        echo "Scraping Harris County permits for the last ${DAYS} days..."
        echo "Sample data mode: ${SAMPLE_DATA}"
        python -m permit_leads scrape --jurisdiction tx-harris --days "${DAYS}" --formats csv sqlite jsonl --verbose
        
        # Count new permits from today's run
        TODAY=$(date +%Y-%m-%d)
        NEW_PERMITS=0
        
        # Check CSV files for permit count
        if [ -f "data/permits/aggregate/permits_${TODAY}.csv" ]; then
          NEW_PERMITS=$(tail -n +2 "data/permits/aggregate/permits_${TODAY}.csv" | wc -l)
        fi
        
        echo "new_permits=${NEW_PERMITS}" >> $GITHUB_OUTPUT
        echo "Found ${NEW_PERMITS} new permits today"
        
    - name: Fail if zero results for 24h
      if: steps.check_recent.outputs.recent_files == '0' && steps.scrape.outputs.new_permits == '0'
      run: |
        echo "❌ No Harris County permits found in the last 24 hours"
        echo "This may indicate a problem with the scraper or data source"
        exit 1
        
    - name: Commit and push data
      if: ${{ steps.scrape.outputs.new_permits != '0' }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        if git diff --staged --quiet; then
          echo "No changes to commit"
          exit 0
        fi
        TODAY=$(date +%Y-%m-%d)
        git commit -m "Update Harris County permit data for ${TODAY}" \
                    -m "${{ steps.scrape.outputs.new_permits }} permits processed" \
                    -m "Automated Harris County scrape"
        git push
        

    - name: Write job summary
      run: |
        echo "### scrape-harris-permits summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- Supabase URL: $([ -n \"${{ secrets.SUPABASE_URL }}\" ] && echo ✅ Set || echo ❌ Not set)" >> $GITHUB_STEP_SUMMARY
        echo "- Supabase Service Key: $([ -n \"${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}\" ] && echo ✅ Set || echo ❌ Not set)" >> $GITHUB_STEP_SUMMARY
        echo "- HC Permits URL: $([ -n \"${{ secrets.HC_ISSUED_PERMITS_URL }}\" ] && echo ✅ Set || echo ❌ Not set)" >> $GITHUB_STEP_SUMMARY


    - name: Set date output
      id: set_date
      run: echo "date=$(date +%Y-%m-%d)" >> $GITHUB_OUTPUT
        
    - name: Upload data artifacts
      if: ${{ steps.scrape.outputs.new_permits != '0' }}
      uses: actions/upload-artifact@v4
      with:
        name: harris-county-permits-${{ steps.set_date.outputs.date }}
        path: data/
        retention-days: 30